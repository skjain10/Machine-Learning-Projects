{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shwet Jain\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4\n",
    "### Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shwet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.stem import PorterStemmer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Data into the dataframe \"df_sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(988, 2)\n"
     ]
    }
   ],
   "source": [
    "df_sentiment = pd.read_csv('/Users/shwet/OneDrive/Desktop/DA_4/HW4_yelp_sentiment.csv')\n",
    "print(df_sentiment.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews sentiment\n",
       "0                           Wow... Loved this place.         p\n",
       "1                                 Crust is not good.         n\n",
       "2          Not tasty and the texture was just nasty.         n\n",
       "3  Stopped by during the late May bank holiday of...         p\n",
       "4  The selection on the menu was great and so wer...         p"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer combines all the options of CountVectorizer and TfidfTransformer in a single model\n",
    "### Using tf-idf vectorizer to change text to feature\n",
    "### Getting rid of all the stop words\n",
    "### An ngram_range of (1, 1) means only unigrams, (1, 2) means unigrams and bigrams, and (2, 2) means only bigrams \n",
    "### We are using unigrams and bigrams i.e (1, 2)\n",
    "### Converting into lower-case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.float64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 2), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=set([u'all', u'just', u\"don't\", u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'o', u'don', u'hadn', u'herself', u'll', u'had', u'should', u'to', u'only', u'won', u'under', u'ours', u'has', u\"should've\", u\"haven't\", u'do', u'them', u'his', u'very', u\"you've\", u..., u'a', u'off', u'i', u'm', u'yours', u\"you'll\", u'so', u'y', u\"she's\", u'the', u'having', u'once']),\n",
       "        strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_rev = df_sentiment.reviews\n",
    "\n",
    "vect = TfidfVectorizer(stop_words = stop_words, ngram_range =(1,2), min_df = 2, lowercase=True)\n",
    "\n",
    "vect.fit(sent_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_rev_tfidf = vect.transform(sent_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<988x968 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 4812 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_rev_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are now forming a Document Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = pd.DataFrame(sent_rev_tfidf.toarray(), columns=vect.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>10 minutes</th>\n",
       "      <th>100</th>\n",
       "      <th>12</th>\n",
       "      <th>20</th>\n",
       "      <th>20 minutes</th>\n",
       "      <th>30</th>\n",
       "      <th>30 min</th>\n",
       "      <th>30 minutes</th>\n",
       "      <th>35</th>\n",
       "      <th>...</th>\n",
       "      <th>wow</th>\n",
       "      <th>wrap</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>years ago</th>\n",
       "      <th>yet</th>\n",
       "      <th>yummy</th>\n",
       "      <th>zero</th>\n",
       "      <th>zero stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 968 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  10 minutes  100   12   20  20 minutes   30  30 min  30 minutes   35  \\\n",
       "0  0.0         0.0  0.0  0.0  0.0         0.0  0.0     0.0         0.0  0.0   \n",
       "1  0.0         0.0  0.0  0.0  0.0         0.0  0.0     0.0         0.0  0.0   \n",
       "2  0.0         0.0  0.0  0.0  0.0         0.0  0.0     0.0         0.0  0.0   \n",
       "3  0.0         0.0  0.0  0.0  0.0         0.0  0.0     0.0         0.0  0.0   \n",
       "4  0.0         0.0  0.0  0.0  0.0         0.0  0.0     0.0         0.0  0.0   \n",
       "\n",
       "   ...       wow  wrap  wrong  year  years  years ago  yet  yummy  zero  \\\n",
       "0  ...  0.572012   0.0    0.0   0.0    0.0        0.0  0.0    0.0   0.0   \n",
       "1  ...  0.000000   0.0    0.0   0.0    0.0        0.0  0.0    0.0   0.0   \n",
       "2  ...  0.000000   0.0    0.0   0.0    0.0        0.0  0.0    0.0   0.0   \n",
       "3  ...  0.000000   0.0    0.0   0.0    0.0        0.0  0.0    0.0   0.0   \n",
       "4  ...  0.000000   0.0    0.0   0.0    0.0        0.0  0.0    0.0   0.0   \n",
       "\n",
       "   zero stars  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  \n",
       "\n",
       "[5 rows x 968 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dtm.values\n",
    "y = df['sentiment'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting of Data into Training and Testing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((790L, 968L), (790L,))\n",
      "((198L, 968L), (198L,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=100)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model using (.fit) the train data and then finding the accuracy on the test data\n",
    "\n",
    "## Trying different values of c to find the highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.51010101010101\n",
      "Accuracy for C=0.25: 0.7424242424242424\n",
      "Accuracy for C=0.5: 0.7525252525252525\n",
      "Accuracy for C=1: 0.7575757575757576\n",
      "Accuracy for C=5: 0.7525252525252525\n",
      "Accuracy for C=7: 0.7474747474747475\n",
      "Accuracy for C=9: 0.7474747474747475\n",
      "Accuracy for C=10: 0.7474747474747475\n",
      "Accuracy for C=13: 0.7575757575757576\n",
      "Accuracy for C=15: 0.7575757575757576\n",
      "Accuracy for C=20: 0.7626262626262627\n",
      "Accuracy for C=22: 0.7626262626262627\n",
      "Accuracy for C=25: 0.7525252525252525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for c in [0.01,0.25,0.5,1,5,7,9,10,13,15,20,22,25]:\n",
    "    \n",
    "    LR = LogisticRegression(C=c)\n",
    "    LR.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_test, LR.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying alternate values of the loss functions and trial error of other parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 76.76767676767676%\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(class_weight= 'balanced', penalty= 'l2',C=25, max_iter=100)\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "print('Accuracy is' + ' ' + str(score*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[70 19]\n",
      " [27 82]]\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n       0.72      0.79      0.75        89\n",
      "           p       0.81      0.75      0.78       109\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       198\n",
      "   macro avg       0.77      0.77      0.77       198\n",
      "weighted avg       0.77      0.77      0.77       198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict = classifier.predict(X_test)\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, predict))\n",
    "print(\"Report:\")\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, ShuffleSplit\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_clf = svm.LinearSVC(max_iter=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different values of C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C':[0.1,0.25,0.5,0.75,1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM took 0.29 seconds\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "start = time()\n",
    "grid_lsvm = GridSearchCV(lin_clf,param_grid,cv=5,scoring=\"accuracy\")\n",
    "grid_lsvm.fit(X_train,y_train)\n",
    "print(\"Linear SVM took %.2f seconds\"\n",
    "       % (time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Parameter for parameter C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lsvm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.75%\n"
     ]
    }
   ],
   "source": [
    "grid_pred = grid_lsvm.predict(X_test)\n",
    "acc= round(metrics.accuracy_score(y_test, grid_pred)*100, 2)\n",
    "print (\"Accuracy: \" + str(acc) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Random Forest Classifier:\n",
      "\n",
      "\n",
      "[[76 13]\n",
      " [37 72]]\n",
      "Classification Report:\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           n       0.67      0.85      0.75        89\n",
      "           p       0.85      0.66      0.74       109\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       198\n",
      "   macro avg       0.76      0.76      0.75       198\n",
      "weighted avg       0.77      0.75      0.75       198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix for Random Forest Classifier:\")\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,grid_pred))\n",
    "print(\"Classification Report:\")\n",
    "print('\\n')\n",
    "print(classification_report(y_test, grid_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks - ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(sent_rev_tfidf, df_sentiment.sentiment, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I tried different activation functions with different hidden layer sizes to get the best accuracy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes = (180, 170, 150, 100),\n",
    "                   activation = 'relu',learning_rate='adaptive',random_state=1, max_iter = 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "19\n",
      "35\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "abc1= nn.fit(X_train,y_train)\n",
    "prediction = abc1.predict(X_test)\n",
    "tn,fp,fn,tp = confusion_matrix(y_test,prediction).ravel()\n",
    "print(tn)\n",
    "print(fp)\n",
    "print(fn)\n",
    "print(tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As this is Python 2, there's an exception for division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7813765182186235\n"
     ]
    }
   ],
   "source": [
    "print( \"Accuracy = \" + str((tn+tp)/(tn+tp+fp+fn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Accuracy: 76.67% \n",
    "\n",
    "# ANN - Accuracy: 78.13%\n",
    "\n",
    "# SVM - Accuracy: 74.75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out of the three models, Artificial Neural Netwrok is the model which gives highest accuracy. Also, ANN takes a lot more time (more computations as it involves 4 hidden layers) when compared to SVM and Logistic Regression. In future, if we have more data, ANN would certainly provide a much better accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
